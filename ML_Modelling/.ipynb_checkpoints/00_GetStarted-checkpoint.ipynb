{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d5e1013-ddb8-4b99-b906-be734ec4d900",
   "metadata": {},
   "source": [
    "### Welcome to the CKW Energy Data Hackday Challenge\n",
    "The Data has already been processed and is ready for building machine learning models on it. This Notebook will help you to first import the data stored in a Blob Storage and then apply a scaler. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f55b6f-5e2e-4783-b0c2-35218dbe973e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math \n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1f6380-bea7-4392-b6cd-732da9d9f0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import and show data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a936a928-6c23-4b60-aaff-8cab8f77e161",
   "metadata": {},
   "source": [
    "The data consists about 1'180'000 rows and 191 columns. We have this much of columns because some values already have been feature engineered. If you want to see the features we have expanded please watch in the folder FeatureEngineering. To get ready for machine learning we need to first scale our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3238e8c4-d60a-4b34-a5eb-553fc6af6e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale the data with a standard scaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)  \n",
    "X_val_scaled = scaler.transform(X_val)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26765bab-e799-46ab-8402-b253e41e5cbb",
   "metadata": {},
   "source": [
    "#### Easy Machine Learning Model with XGBoostRegressor\n",
    "Now we try to build our machine learning model with XGBoost. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c21ad9-373a-44ae-ab63-8daf3b7a5aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize XGBoost Regressor model\n",
    "model = xgb.XGBRegressor(\n",
    "    n_estimators=100,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.1,\n",
    "    random_state=42,\n",
    "    objective='reg:squarederror'\n",
    ")\n",
    "\n",
    "# train model on scaled train data\n",
    "model.fit(X_train_scaled, y_Train)\n",
    "\n",
    "# predict y with validation data\n",
    "y_pred = model.predict(X_val_scaled)\n",
    "\n",
    "# measure performance values\n",
    "mse = mean_squared_error(y_val, y_pred)\n",
    "r2 = r2_score(y_val, y_pred)\n",
    "mae = mean_absolute_error(y_val, y_pred)\n",
    "\n",
    "print(f\"Validation MSE: {mse:.4f}\")\n",
    "print(f\"Validation R2: {r2:.4f}\")\n",
    "print(f\"Validation MAE: {mae:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fabda452-b90e-4388-97af-73c2f7bfe065",
   "metadata": {},
   "source": [
    "As you can see, our model is already pretty good in performance. If you are happy with the model save it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "533ce829-f8f8-41f3-a79b-3e30525829be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: save Model\n",
    "# model.save_model(\"01_Models/xgb_regressor_model_with_feed_in.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5bee04a-6234-42f1-a80b-6ea38089a5c1",
   "metadata": {},
   "source": [
    "#### Model Insights\n",
    "In this step we will see what kind of features have the most influence on the predicted value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3afc51-18f1-4b10-b306-9215fda99af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = model.feature_importances_\n",
    "feature_names = X_train.columns if hasattr(X_train, 'columns') else [f'feature_{i}' for i in range(X_train.shape[1])]\n",
    "\n",
    "# Sortieren\n",
    "sorted_idx = np.argsort(importances)[::-1]\n",
    "top_n = 15  # Anzahl der Top-Features\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "bars = plt.bar(range(top_n), importances[sorted_idx][:top_n], color='skyblue')\n",
    "plt.xticks(range(top_n), [feature_names[i] for i in sorted_idx][:top_n], rotation=45, ha='right')\n",
    "plt.title('Top Feature Importances')\n",
    "plt.ylabel('Importance')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Werte über Balken anzeigen\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, height, f'{height:.3f}', ha='center', va='bottom')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e174ea8e-6dbc-4b66-aa04-ce81995f6d7c",
   "metadata": {},
   "source": [
    "As you can see, the feed in feature has the biggest impact on the final predicted value. also the global radiation and the panel peak power have good influences on the model. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c0c090-2337-423f-8696-88ec9d7282f2",
   "metadata": {},
   "source": [
    "#### Model without feed in feature\n",
    "As a hard test we try to forecast a value where we don't know the true value of the feed in energy.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c6e4ce1-7515-43d2-ad30-31aa70ca40f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove feed in features \n",
    "ueberschuss_cols = [col for col in X_train.columns if 'Überschuss' in col]\n",
    "cols_to_remove = ueberschuss_cols + ['feed_in:kWh']\n",
    "cols_to_keep = [col for col in X_train.columns if col not in cols_to_remove]\n",
    "\n",
    "X_train_scaled_without_feed_in = X_train_scaled[:, [X_train.columns.get_loc(col) for col in cols_to_keep]]\n",
    "X_val_scaled_without_feed_in = X_val_scaled[:, [X_val.columns.get_loc(col) for col in cols_to_keep]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6cc8f36-117b-49bc-919e-279e9ab20343",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize XGBoost Regressor model\n",
    "model = xgb.XGBRegressor(\n",
    "    n_estimators=100,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.1,\n",
    "    random_state=42,\n",
    "    objective='reg:squarederror'\n",
    ")\n",
    "\n",
    "# train model on scaled train data\n",
    "model.fit(X_train_scaled_without_feed_in, y_Train)\n",
    "\n",
    "# predict y with validation data\n",
    "y_pred_wo_feed_in = model.predict(X_val_scaled_without_feed_in)\n",
    "\n",
    "# measure performance values\n",
    "mse = mean_squared_error(y_val, y_pred_wo_feed_in)\n",
    "r2 = r2_score(y_val, y_pred_wo_feed_in)\n",
    "mae = mean_absolute_error(y_val, y_pred)\n",
    "\n",
    "print(f\"Validation MSE: {mse:.4f}\")\n",
    "print(f\"Validation R2: {r2:.4f}\")\n",
    "print(f\"Validation MAE: {mae:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48533699-60f0-4453-bb5a-9f3b73c67b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: save model\n",
    "# model.save_model(\"01_Models/xgb_regressor_model_without_feed_in.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb17fbbb-1967-4186-a139-74de535cb9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = model.feature_importances_\n",
    "feature_names = cols_to_keep\n",
    "\n",
    "# Sortieren\n",
    "sorted_idx = np.argsort(importances)[::-1]\n",
    "top_n = 15  # Anzahl der Top-Features\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "bars = plt.bar(range(top_n), importances[sorted_idx][:top_n], color='skyblue')\n",
    "plt.xticks(range(top_n), [feature_names[i] for i in sorted_idx][:top_n], rotation=45, ha='right')\n",
    "plt.title('Top Feature Importances')\n",
    "plt.ylabel('Importance')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Werte über Balken anzeigen\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, height, f'{height:.3f}', ha='center', va='bottom')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b1099c-ca51-44ae-bf46-522608c6b61b",
   "metadata": {},
   "source": [
    "As you can see the model performs worse, because very important features are missing now. The key discipline is to improve this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef42f17b-8fda-4269-ab72-1ee429bcd963",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a scatterplot to visualize the true vs the predicted values of both models\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_val, y_pred_wo_feed_in, alpha=0.1, color='blue', label='Ohne Rückspeisemessug')\n",
    "plt.scatter(y_val, y_pred, alpha=0.1, color='green', label='Mit Rückspeisemessug')\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# without feed in feature\n",
    "axes[0].scatter(y_val, y_pred_wo_feed_in, alpha=0.1, color='blue')\n",
    "axes[0].plot([0, 12], [0, 12], linestyle='--', color='red', label='Perfektes Modell')\n",
    "axes[0].set_title('Ohne Rückspeisemessung')\n",
    "axes[0].set_xlabel('Wahre Werte')\n",
    "axes[0].set_ylabel('Vorhergesagte Werte')\n",
    "axes[0].legend()\n",
    "axes[0].grid()\n",
    "\n",
    "# model with feed in feature\n",
    "axes[1].scatter(y_val, y_pred, alpha=0.1, color='green')\n",
    "axes[1].plot([0, 12], [0, 12], linestyle='--', color='red', label='Perfektes Modell')\n",
    "axes[1].set_title('Mit Rückspeisemessung')\n",
    "axes[1].set_xlabel('Wahre Werte')\n",
    "axes[1].set_ylabel('Vorhergesagte Werte')\n",
    "axes[1].legend()\n",
    "axes[1].grid()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
